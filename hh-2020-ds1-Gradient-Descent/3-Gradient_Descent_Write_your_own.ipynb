{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple gradient Descent Algorithm is as follows:\n",
    "1. Obtain a function to minimize F(x)\n",
    "\n",
    "2. Initialize a value x from which to start the descent or optimization from\n",
    "\n",
    "3. Specify a learning rate that will determine how much of a step to descend by or how quickly you converge to the minimum value\n",
    "\n",
    "4. Obtain the derivative of that value x (the descent)\n",
    "\n",
    "5. Proceed to descend by the derivative of that value multiplied by the learning rate\n",
    "\n",
    "6. Update the value of x with the new value descended to\n",
    "\n",
    "7. Check your stop condition to see whether to stop\n",
    "\n",
    "8. If condition satisfied, stop. If not, proceed to step 4 with the new x value and keep repeating algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us implement this in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a simple representation of gradient descent using python. \n",
    "\n",
    "We will create an arbitrary loss function and attempt to find a local minimum value for that function— f(x) = x³ — 3x² + 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first visualize this function with a set of values ranging from -1 and 3 (arbitrarily chosen to ensure steep curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating the function and plotting it \n",
    "\n",
    "function = \n",
    "\n",
    "\n",
    "#Get 1000 evenly spaced numbers between -1 and 3 (arbitratil chosen to ensure steep curve)\n",
    "\n",
    "\n",
    "#Plot the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then proceed to make two functions for the gradient descent implementation:\n",
    "\n",
    "The first is a derivative function: \n",
    "\n",
    "\n",
    "This function takes in a value of x and returns its derivative based on the initial function we specified. It is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deriv(x):\n",
    "    \n",
    "    '''\n",
    "    Description: This function takes in a value of x and returns its derivative based on the \n",
    "    initial function we specified.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    x - a numerical value of x \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    x_deriv - a numerical value of the derivative of x\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return x_deriv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second is a Step function: \n",
    "\n",
    "\n",
    "This is the function where the actual gradient descent takes place. \n",
    "\n",
    "\n",
    "\n",
    "This function takes in an initial or previous value for x, updates it based on steps taken via the learning rate and outputs the most minimum value of x that reaches the stop condition. \n",
    "\n",
    "\n",
    "\n",
    "For our stop condition, we are going to use a precision stop.\n",
    "\n",
    "\n",
    "\n",
    "This means that when the absolute difference between our old and updated x is greater than a value, the algorithm should stop. \n",
    "\n",
    "\n",
    "\n",
    "The function will also print out the minimum value of x as well as the number of steps or descents it took to reach that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "def step(x_new, x_prev, precision, l_r):\n",
    "    \n",
    "    '''\n",
    "    Description: This function takes in an initial or previous value for x, updates it based on \n",
    "    steps taken via the learning rate and outputs the most minimum value of x that reaches the precision satisfaction.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    x_new - a starting value of x that will get updated based on the learning rate\n",
    "    \n",
    "    x_prev - the previous value of x that is getting updated to the new one\n",
    "    \n",
    "    precision - a precision that determines the stop of the stepwise descent \n",
    "    \n",
    "    l_r - the learning rate (size of each descent step)\n",
    "    \n",
    "    Output:\n",
    "    \n",
    "    1. Prints out the latest new value of x which equates to the minimum we are looking for\n",
    "    2. Prints out the the number of x values which equates to the number of gradient descent steps\n",
    "    3. Plots a first graph of the function with the gradient descent path\n",
    "    4. Plots a second graph of the function with a zoomed in gradient descent path in the important area\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # create empty lists where the updated values of x and y wil be appended during each iteration\n",
    "    \n",
    "    \n",
    "    # keep looping until your desired precision\n",
    "    \n",
    "        \n",
    "        # change the value of x\n",
    "        \n",
    "        \n",
    "        # get the derivation of the old value of x\n",
    "        \n",
    "        \n",
    "        # get your new value of x by adding the previous, the multiplication of the derivative and the learning rate\n",
    "        \n",
    "        \n",
    "        # append the new value of x to a list of all x-s for later visualization of path\n",
    "        \n",
    "        \n",
    "        # append the new value of y to a list of all y-s for later visualization of path\n",
    "       \n",
    "\n",
    "    print (\"Local minimum occurs at: \"+ str(x_new))\n",
    "    print (\"Number of steps: \" + str(len(x_list)))\n",
    "    \n",
    "    # Create plot to show Gradient descent, \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implement gradient descent (all the arguments are arbitrarily chosen)\n",
    "\n",
    "step(0.5, 0, 0.001, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ds1] *",
   "language": "python",
   "name": "conda-env-ds1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
